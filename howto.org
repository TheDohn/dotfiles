#+TITLE: Various How To


* Docker

** questions:
- when specifying requirements.txt, how do you initially determine the pandas version?
  - I assume from building it first w/o Docker? no, that seems wrong.

** basic workflow

- write a Dockerfile
- in that directory, $ docker build .
- find the image w $ docker image ls
- run the image with $ docker run <image_id>

** for building a specific stage

- in that directory, $ docker build --target <stage> .

and potentially, if we want to force it to rebuild from scratch:


$ docker build --no-cache --target <stage> .

** how to:

- write Dockerfile

to build image from Dockerfile:
$ docker build .
+ not that for Rockerverse, and maybe other images I need to build w flag --platform linux/x86_64
(what is the better way to be more specific here?)

or specify the image name as:
$ docker build -t <name> .
$ docker build -t dons_dc_example .

get image name from
$ docker image ls

run interactively (starts container, and then drops you in the shell)
$ docker run -it <image_name> bash
$ docker run -it ccc51f4c6e41 bash
some ppl I see do `docker run -it <image_name> /bin/bash but either way seems to work

+ if the container is *already running*, then you can do:
$ docker exec -it <container_name> bash
However, I think you typically need some sort of long-lived process to keep it running for this to work.
And the run command above seems to work for me better.

*** for compose and volume mounts:

I may need to run:
$ docker compose build
+ may need to add some sort of platform flag for the above, which I haven't figured out yet
  + I think adding the platform right to the Dockerfile is the way to go

$ docker compose run <app ref'd in compose yaml>
 + note that sometimes the above starts python at the shell (maybe the base image is doing this?)
   at any rate, running $ docker compose run <app in compose yaml> bash
   will make it start up the shell

typically you want to run the compose in the background, otherwise you don't get a prompt back in that terminal, so:
$ docker compose up -d


get running containers:
$ docker ps

*** verify mounts

https://stackoverflow.com/questions/30133664/how-do-you-list-volumes-in-docker-containers
docker inspect -f '{{ .Mounts }}' containerid

** Docker in EC2:

install Docker:
https://serverfault.com/questions/836198/how-to-install-docker-on-aws-ec2-instance-with-ami-ce-ee-update

then fix permissions:
https://stackoverflow.com/questions/48957195/how-to-fix-docker-got-permission-denied-issue

I may need to install this, too, I forget:
https://stackoverflow.com/questions/3160909/how-do-i-deal-with-certificates-using-curl-while-trying-to-access-an-https-url

** ray docker/Apple silicon:

I think the only why I was able to get this to work was when I had the following specified:
export DOCKER_DEFAULT_PLATFORM=linux/amd64
this also seemed to work
export DOCKER_DEFAULT_PLATFORM=linux/x86_64
I may have also need to pass the --platform linux/arm64 when I built or run the Docker image, but I don't think so

that said, I am not clear if this actually completely fixes things since I think there is still an
"amd64" warning in the list of containers in the Docker Desktop GUI

both pulling an image with the flag --platform/linux/arm64 and running it to seems to work for Python image at least
i.e.:
1) docker pull --platform=linux/arm64 python
2) docker run --platform=linux/arm64 -it python /bin/bash
!!!I DON'T think the above works for Ray images!!!

this might work for Ray, in that it doesn't give errors, but it still runs amd64, and so the Docker GUI
gives a warning
docker pull --platform=linux/x86_64 rayproject/ray
docker run --platform=linux/x86_64 -it rayproject/ray /bin/bash

** get root access

sometimes containers don't give you root access (ex: Ray containers start you with the "ray" user)
to get root access"
$docker exec -u 0 -it d9eff43f038c bash

** TODO
*** figure out how to pull my dotfiles
- this might cause issues since they are not necessarily made for Linux

*** didn't I have instructions for connecting to EC2 inside spacemacs, for ESS specifically, maybe?

that might be in spacemacs_howto

* Ray

I was able to get the following to work:

just auth at the CL as usual

1) ray up example-full.yaml (this can take awhile, but seems to be faster with CPU variant)
- note that you may need to wait and verify that EC2 is finished initializing, before 2 below
2) ray submit example-full.yaml test.py (I don't think you can just run this w/o step #1)

- either arguments can be a relative path i.e. dir/example-full.yaml


TODO: understand how to view the Ray dashboard in this case

to see the dashboard:

ray dashboard example-full.yaml and get port

I forget exactly, but the following may have been what I following to get that working:
https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/aws.html?highlight=aws

This was working, but when I tried on <2024-06-04 Tue> I got an error,
which I think was just due to a command I had in the yaml, like:
$ sudo apt-get update



     Reading package lists... Done
     E: The repository 'http://apt.kubernetes.io kubernetes-xenial Release' does not have a Release file.
     N: Updating from such a repository can't be done securely, and is therefore disabled by default.
     N: See apt-secure(8) manpage for repository creation and user configuration details.
     Shared connection to 34.210.182.181 closed.
     New status: update-failed
     !!!
     SSH command failed.
     !!!

     Failed to setup head node.


** TODO
- just familiarize myself with the Ray cluster yaml file
- figure out how to submit Ray jobs so I am not just watching the command line
- get AWS cloudwatch going
 https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/aws.html#aws-configurations

** debug

basically follow these instructions:
https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html
- add browser() to you script
- source that script
- then run `ray debug` in another terminal
  
I think a subtlety comes up is if that browser() isn't nested inside something that requires Ray,
this will actually default to the workflow of the vanilla Python debugger, which can be confusing
https://docs.python.org/3/library/pdb.html

* AWS
** create a new role and assume it

1) Add the new role in the web gui
2) Add a trust policy for your current role (like platform-sandbox-admin) so the trust policy looks something like:

{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:sts::###########:assumed-role/AWSReservedSSO_SandboxAdminAccess_###########/XXXXX@ixisdigital.com",
                "Service": "ec2.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

3) may need to reauthenticate at the CL
4) then run:
aws sts assume-role --role-arn "arn:aws:iam::ACCOUNT-ID:role/my-iam-role" --role-session-name <my-role-session>

+ the arn is from the gui for that new role
+ the role-session name is made up on the spot

This can be useful for verifying policies for a role:

 aws iam list-attached-role-policies --role-name <role-name>

need this from time-to-time:

export AWS_ACCESS_KEY_ID=
export AWS_SECRET_ACCESS_KEY=
export AWS_SESSION_TOKEN=

* Python

** debugging

*** post-mortem debugging

https://www.youtube.com/watch?v=s8Nx2frW4ps

run script as:

- $ python -m pdb <script.py>
- debugger seems to start, but just enter 'c' to continue
- then the script will crash, /then/ it will enter an interactive debugger

NOTE that this does NOT seem to work for pdb++
https://github.com/pdbpp/pdbpp

pdb++ has some nice stuff, like sticky mode

pudb also works
- ctrl+x to go between the source and the REPL

* aider

** inside a repo
I have my config set so I can just run
$ aider --model default

** outside a git repo

$ aider --model default --no-git

* dbt
** compile model

$ dbt compile -s aoa_xi_fs_con_visits_test_v5 --vars '{start_date: "2024-03-01", end_date: "2024-04-01"}' --quiet

this will compile to an executable SQL script in, for example:

/ds-data-refinery/src/dbt/projects/client=aoa/target/compiled/ixis_athena_aoa/models/aoa_experience_index/aoa_xi_fs_con_visits_test_v5.sql


** build

$ dbt build -s aoa_xi_fs_con_visits_test_v5 --vars '{start_date: "2024-03-01", end_date: "2024-03-03"}' --quiet

* CLI

** keep iterm awake

$ caffeinate -disu -t $((60*60*<hours>))
